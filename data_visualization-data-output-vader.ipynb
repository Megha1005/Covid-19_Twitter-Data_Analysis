{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Libraries for wordcloud making and image importing\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from PIL import Image\n",
    "\n",
    "# And libraries for data transformation\n",
    "import datetime\n",
    "\n",
    "#words counter\n",
    "from collections import Counter\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "# sentiment \n",
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/allen/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3254: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "files = ['csv/2020-01-final.csv', 'csv/2020-02-final.csv', 'csv/2020-03-final.csv', 'csv/2020-04-final.csv', 'csv/2020-05-final.csv']\n",
    "# read files\n",
    "df_month = [pd.read_csv(i) for i in files]\n",
    "# concatenate files\n",
    "df = pd.concat(df_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15205667 entries, 0 to 960492\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Dtype \n",
      "---  ------              ----- \n",
      " 0   id_str              object\n",
      " 1   created_at          object\n",
      " 2   state               object\n",
      " 3   sentiment           object\n",
      " 4   text_clean          object\n",
      " 5   afn_sentiment       object\n",
      " 6   vader_sentiment     object\n",
      " 7   ensemble_sentiment  object\n",
      "dtypes: object(8)\n",
      "memory usage: 1.0+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_str                      0\n",
       "created_at                210\n",
       "state                 1040415\n",
       "sentiment                   0\n",
       "text_clean             105700\n",
       "afn_sentiment          105700\n",
       "vader_sentiment        105700\n",
       "ensemble_sentiment          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15099967 entries, 0 to 960492\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Dtype \n",
      "---  ------              ----- \n",
      " 0   id_str              object\n",
      " 1   created_at          object\n",
      " 2   state               object\n",
      " 3   sentiment           object\n",
      " 4   text_clean          object\n",
      " 5   afn_sentiment       object\n",
      " 6   vader_sentiment     object\n",
      " 7   ensemble_sentiment  object\n",
      "dtypes: object(8)\n",
      "memory usage: 1.0+ GB\n"
     ]
    }
   ],
   "source": [
    "# delete the null row by 'text_clean'\n",
    "df = df[df['text_clean'].notna()]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_str                      0\n",
       "created_at                210\n",
       "state                 1032616\n",
       "sentiment                   0\n",
       "text_clean                  0\n",
       "afn_sentiment               0\n",
       "vader_sentiment             0\n",
       "ensemble_sentiment          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14067351 entries, 0 to 960492\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Dtype \n",
      "---  ------              ----- \n",
      " 0   id_str              object\n",
      " 1   created_at          object\n",
      " 2   state               object\n",
      " 3   sentiment           object\n",
      " 4   text_clean          object\n",
      " 5   afn_sentiment       object\n",
      " 6   vader_sentiment     object\n",
      " 7   ensemble_sentiment  object\n",
      "dtypes: object(8)\n",
      "memory usage: 965.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# delete the null row by 'state'\n",
    "df = df[df['state'].notna()]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_str</th>\n",
       "      <th>created_at</th>\n",
       "      <th>state</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>afn_sentiment</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>ensemble_sentiment</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1219856157608566784</td>\n",
       "      <td>Wed Jan 22 05:35:46 +0000 2020</td>\n",
       "      <td>California</td>\n",
       "      <td>positive</td>\n",
       "      <td>momsdemand brendaof fun fact  accidental death...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1/22/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1219856816114487296</td>\n",
       "      <td>Wed Jan 22 05:38:23 +0000 2020</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>positive</td>\n",
       "      <td>troopax johnmaamd ravin coqundoodledoo edwardh...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>1/22/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1219856906270990336</td>\n",
       "      <td>Wed Jan 22 05:38:44 +0000 2020</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>negative</td>\n",
       "      <td>brutal season protect yourself</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>1/22/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1219857010696630272</td>\n",
       "      <td>Wed Jan 22 05:39:09 +0000 2020</td>\n",
       "      <td>New York</td>\n",
       "      <td>positive</td>\n",
       "      <td>wish administrators cdc could impeached failin...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>1/22/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1219858026242416640</td>\n",
       "      <td>Wed Jan 22 05:43:11 +0000 2020</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>positive</td>\n",
       "      <td>united states first confirmed case new virus a...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>1/22/20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id_str                      created_at         state  \\\n",
       "0  1219856157608566784  Wed Jan 22 05:35:46 +0000 2020    California   \n",
       "2  1219856816114487296  Wed Jan 22 05:38:23 +0000 2020     Wisconsin   \n",
       "3  1219856906270990336  Wed Jan 22 05:38:44 +0000 2020  Pennsylvania   \n",
       "4  1219857010696630272  Wed Jan 22 05:39:09 +0000 2020      New York   \n",
       "6  1219858026242416640  Wed Jan 22 05:43:11 +0000 2020    New Jersey   \n",
       "\n",
       "  sentiment                                         text_clean afn_sentiment  \\\n",
       "0  positive  momsdemand brendaof fun fact  accidental death...      negative   \n",
       "2  positive  troopax johnmaamd ravin coqundoodledoo edwardh...      negative   \n",
       "3  negative                    brutal season protect yourself       negative   \n",
       "4  positive  wish administrators cdc could impeached failin...      negative   \n",
       "6  positive  united states first confirmed case new virus a...      negative   \n",
       "\n",
       "  vader_sentiment ensemble_sentiment     date  \n",
       "0        positive            neutral  1/22/20  \n",
       "2        negative           negative  1/22/20  \n",
       "3        negative           negative  1/22/20  \n",
       "4        negative           negative  1/22/20  \n",
       "6        negative           negative  1/22/20  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, datetime\n",
    "def extract_date(x):\n",
    "#     match = re.search('\\d{2}-\\d{2}', x)\n",
    "#     date = datetime.datetime.strptime(match.group(), '%m-%d').date()\n",
    "    x_list = x.split(' ')\n",
    "    month = '1' if x_list[1] == 'Jan' else '2' if x_list[1] == 'Feb' else '3' if x_list[1] =='Mar' else '4' if x_list[1] == 'Apr' else '5' if x_list[1] == 'May' else'others'\n",
    "    if len(x_list[2]) == 1:\n",
    "        x_list[2] = '0' + x_list[2]\n",
    "    date = month + '/' + x_list[2] + '/' + '20'\n",
    "    return date\n",
    "df['date'] = df['created_at'].apply(lambda x: extract_date(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target sentiment\n",
    "df['sentiment'] = df['vader_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14067351 entries, 0 to 960492\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Dtype \n",
      "---  ------              ----- \n",
      " 0   id_str              object\n",
      " 1   created_at          object\n",
      " 2   state               object\n",
      " 3   sentiment           object\n",
      " 4   text_clean          object\n",
      " 5   afn_sentiment       object\n",
      " 6   vader_sentiment     object\n",
      " 7   ensemble_sentiment  object\n",
      " 8   date                object\n",
      "dtypes: object(9)\n",
      "memory usage: 1.0+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_str</th>\n",
       "      <th>created_at</th>\n",
       "      <th>state</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>afn_sentiment</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>ensemble_sentiment</th>\n",
       "      <th>date</th>\n",
       "      <th>state_abb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1219856157608566784</td>\n",
       "      <td>Wed Jan 22 05:35:46 +0000 2020</td>\n",
       "      <td>California</td>\n",
       "      <td>positive</td>\n",
       "      <td>momsdemand brendaof fun fact  accidental death...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1219856816114487296</td>\n",
       "      <td>Wed Jan 22 05:38:23 +0000 2020</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>negative</td>\n",
       "      <td>troopax johnmaamd ravin coqundoodledoo edwardh...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1219856906270990336</td>\n",
       "      <td>Wed Jan 22 05:38:44 +0000 2020</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>negative</td>\n",
       "      <td>brutal season protect yourself</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1219857010696630272</td>\n",
       "      <td>Wed Jan 22 05:39:09 +0000 2020</td>\n",
       "      <td>New York</td>\n",
       "      <td>negative</td>\n",
       "      <td>wish administrators cdc could impeached failin...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1219858026242416640</td>\n",
       "      <td>Wed Jan 22 05:43:11 +0000 2020</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>negative</td>\n",
       "      <td>united states first confirmed case new virus a...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id_str                      created_at         state  \\\n",
       "0  1219856157608566784  Wed Jan 22 05:35:46 +0000 2020    California   \n",
       "2  1219856816114487296  Wed Jan 22 05:38:23 +0000 2020     Wisconsin   \n",
       "3  1219856906270990336  Wed Jan 22 05:38:44 +0000 2020  Pennsylvania   \n",
       "4  1219857010696630272  Wed Jan 22 05:39:09 +0000 2020      New York   \n",
       "6  1219858026242416640  Wed Jan 22 05:43:11 +0000 2020    New Jersey   \n",
       "\n",
       "  sentiment                                         text_clean afn_sentiment  \\\n",
       "0  positive  momsdemand brendaof fun fact  accidental death...      negative   \n",
       "2  negative  troopax johnmaamd ravin coqundoodledoo edwardh...      negative   \n",
       "3  negative                    brutal season protect yourself       negative   \n",
       "4  negative  wish administrators cdc could impeached failin...      negative   \n",
       "6  negative  united states first confirmed case new virus a...      negative   \n",
       "\n",
       "  vader_sentiment ensemble_sentiment     date state_abb  \n",
       "0        positive            neutral  1/22/20        CA  \n",
       "2        negative           negative  1/22/20        WI  \n",
       "3        negative           negative  1/22/20        PA  \n",
       "4        negative           negative  1/22/20        NY  \n",
       "6        negative           negative  1/22/20        NJ  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from settings import states_full_dic\n",
    "df['state_abb'] = df['state'].apply(lambda x: states_full_dic[x] if x is not np.nan else x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Correlation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Correlation of total tweets and cases for each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>...</th>\n",
       "      <th>5/5/20</th>\n",
       "      <th>5/6/20</th>\n",
       "      <th>5/7/20</th>\n",
       "      <th>5/8/20</th>\n",
       "      <th>5/9/20</th>\n",
       "      <th>5/10/20</th>\n",
       "      <th>5/11/20</th>\n",
       "      <th>5/12/20</th>\n",
       "      <th>5/13/20</th>\n",
       "      <th>5/14/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>AS</td>\n",
       "      <td>ASM</td>\n",
       "      <td>16</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>US</td>\n",
       "      <td>-14.2710</td>\n",
       "      <td>-170.1320</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>316</td>\n",
       "      <td>GU</td>\n",
       "      <td>GUM</td>\n",
       "      <td>316</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Guam</td>\n",
       "      <td>US</td>\n",
       "      <td>13.4443</td>\n",
       "      <td>144.7937</td>\n",
       "      <td>...</td>\n",
       "      <td>145</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>152</td>\n",
       "      <td>152</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>580</td>\n",
       "      <td>MP</td>\n",
       "      <td>MNP</td>\n",
       "      <td>580</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern Mariana Islands</td>\n",
       "      <td>US</td>\n",
       "      <td>15.0979</td>\n",
       "      <td>145.6739</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>630</td>\n",
       "      <td>PR</td>\n",
       "      <td>PRI</td>\n",
       "      <td>630</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>US</td>\n",
       "      <td>18.2208</td>\n",
       "      <td>-66.5901</td>\n",
       "      <td>...</td>\n",
       "      <td>1924</td>\n",
       "      <td>1968</td>\n",
       "      <td>2031</td>\n",
       "      <td>2156</td>\n",
       "      <td>2173</td>\n",
       "      <td>2198</td>\n",
       "      <td>2256</td>\n",
       "      <td>2299</td>\n",
       "      <td>2329</td>\n",
       "      <td>2427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>VI</td>\n",
       "      <td>VIR</td>\n",
       "      <td>850</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin Islands</td>\n",
       "      <td>US</td>\n",
       "      <td>18.3358</td>\n",
       "      <td>-64.8963</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UID iso2 iso3  code3  FIPS Admin2            Province_State Country_Region  \\\n",
       "0   16   AS  ASM     16  60.0    NaN            American Samoa             US   \n",
       "1  316   GU  GUM    316  66.0    NaN                      Guam             US   \n",
       "2  580   MP  MNP    580  69.0    NaN  Northern Mariana Islands             US   \n",
       "3  630   PR  PRI    630  72.0    NaN               Puerto Rico             US   \n",
       "4  850   VI  VIR    850  78.0    NaN            Virgin Islands             US   \n",
       "\n",
       "       Lat     Long_  ... 5/5/20  5/6/20  5/7/20  5/8/20  5/9/20  5/10/20  \\\n",
       "0 -14.2710 -170.1320  ...      0       0       0       0       0        0   \n",
       "1  13.4443  144.7937  ...    145     149     149     151     151      151   \n",
       "2  15.0979  145.6739  ...     14      15      15      15      16       16   \n",
       "3  18.2208  -66.5901  ...   1924    1968    2031    2156    2173     2198   \n",
       "4  18.3358  -64.8963  ...     66      66      66      68      68       69   \n",
       "\n",
       "   5/11/20  5/12/20  5/13/20  5/14/20  \n",
       "0        0        0        0        0  \n",
       "1      151      152      152      152  \n",
       "2       19       19       19       19  \n",
       "3     2256     2299     2329     2427  \n",
       "4       69       69       69       69  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us = pd.read_csv('csv/time_series_covid19_confirmed_US.csv')\n",
    "df_us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>UID</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>...</th>\n",
       "      <th>5/5/20</th>\n",
       "      <th>5/6/20</th>\n",
       "      <th>5/7/20</th>\n",
       "      <th>5/8/20</th>\n",
       "      <th>5/9/20</th>\n",
       "      <th>5/10/20</th>\n",
       "      <th>5/11/20</th>\n",
       "      <th>5/12/20</th>\n",
       "      <th>5/13/20</th>\n",
       "      <th>5/14/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5796241491</td>\n",
       "      <td>57960</td>\n",
       "      <td>241491.0</td>\n",
       "      <td>2203.246784</td>\n",
       "      <td>-5809.578199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8437</td>\n",
       "      <td>8691</td>\n",
       "      <td>9046</td>\n",
       "      <td>9385</td>\n",
       "      <td>9668</td>\n",
       "      <td>9889</td>\n",
       "      <td>10164</td>\n",
       "      <td>10464</td>\n",
       "      <td>10700</td>\n",
       "      <td>11101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2604232344</td>\n",
       "      <td>26040</td>\n",
       "      <td>232344.0</td>\n",
       "      <td>1747.579877</td>\n",
       "      <td>-4229.319334</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>371</td>\n",
       "      <td>372</td>\n",
       "      <td>374</td>\n",
       "      <td>377</td>\n",
       "      <td>378</td>\n",
       "      <td>379</td>\n",
       "      <td>379</td>\n",
       "      <td>383</td>\n",
       "      <td>383</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-14.271000</td>\n",
       "      <td>-170.132000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>1428230216</td>\n",
       "      <td>14280</td>\n",
       "      <td>230216.0</td>\n",
       "      <td>505.138555</td>\n",
       "      <td>-1671.948482</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9305</td>\n",
       "      <td>9707</td>\n",
       "      <td>9945</td>\n",
       "      <td>10526</td>\n",
       "      <td>10960</td>\n",
       "      <td>11119</td>\n",
       "      <td>11383</td>\n",
       "      <td>11736</td>\n",
       "      <td>12216</td>\n",
       "      <td>12674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>6468550635</td>\n",
       "      <td>64680</td>\n",
       "      <td>550635.0</td>\n",
       "      <td>2618.391704</td>\n",
       "      <td>-6932.548370</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3525</td>\n",
       "      <td>3611</td>\n",
       "      <td>3703</td>\n",
       "      <td>3747</td>\n",
       "      <td>3747</td>\n",
       "      <td>4012</td>\n",
       "      <td>4043</td>\n",
       "      <td>4164</td>\n",
       "      <td>4236</td>\n",
       "      <td>4366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Province_State         UID  code3      FIPS          Lat        Long_  \\\n",
       "0         Alabama  5796241491  57960  241491.0  2203.246784 -5809.578199   \n",
       "1          Alaska  2604232344  26040  232344.0  1747.579877 -4229.319334   \n",
       "2  American Samoa          16     16      60.0   -14.271000  -170.132000   \n",
       "3         Arizona  1428230216  14280  230216.0   505.138555 -1671.948482   \n",
       "4        Arkansas  6468550635  64680  550635.0  2618.391704 -6932.548370   \n",
       "\n",
       "   1/22/20  1/23/20  1/24/20  1/25/20  ...  5/5/20  5/6/20  5/7/20  5/8/20  \\\n",
       "0        0        0        0        0  ...    8437    8691    9046    9385   \n",
       "1        0        0        0        0  ...     371     372     374     377   \n",
       "2        0        0        0        0  ...       0       0       0       0   \n",
       "3        0        0        0        0  ...    9305    9707    9945   10526   \n",
       "4        0        0        0        0  ...    3525    3611    3703    3747   \n",
       "\n",
       "   5/9/20  5/10/20  5/11/20  5/12/20  5/13/20  5/14/20  \n",
       "0    9668     9889    10164    10464    10700    11101  \n",
       "1     378      379      379      383      383      383  \n",
       "2       0        0        0        0        0        0  \n",
       "3   10960    11119    11383    11736    12216    12674  \n",
       "4    3747     4012     4043     4164     4236     4366  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_states = df_us.groupby('Province_State').sum().reset_index()\n",
    "df_states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>1/28/20</th>\n",
       "      <th>1/29/20</th>\n",
       "      <th>1/30/20</th>\n",
       "      <th>...</th>\n",
       "      <th>5/7/20</th>\n",
       "      <th>5/8/20</th>\n",
       "      <th>5/9/20</th>\n",
       "      <th>5/10/20</th>\n",
       "      <th>5/11/20</th>\n",
       "      <th>5/12/20</th>\n",
       "      <th>5/13/20</th>\n",
       "      <th>5/14/20</th>\n",
       "      <th>state</th>\n",
       "      <th>state_abb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9046</td>\n",
       "      <td>9385</td>\n",
       "      <td>9668</td>\n",
       "      <td>9889</td>\n",
       "      <td>10164</td>\n",
       "      <td>10464</td>\n",
       "      <td>10700</td>\n",
       "      <td>11101</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>374</td>\n",
       "      <td>377</td>\n",
       "      <td>378</td>\n",
       "      <td>379</td>\n",
       "      <td>379</td>\n",
       "      <td>383</td>\n",
       "      <td>383</td>\n",
       "      <td>383</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9945</td>\n",
       "      <td>10526</td>\n",
       "      <td>10960</td>\n",
       "      <td>11119</td>\n",
       "      <td>11383</td>\n",
       "      <td>11736</td>\n",
       "      <td>12216</td>\n",
       "      <td>12674</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3703</td>\n",
       "      <td>3747</td>\n",
       "      <td>3747</td>\n",
       "      <td>4012</td>\n",
       "      <td>4043</td>\n",
       "      <td>4164</td>\n",
       "      <td>4236</td>\n",
       "      <td>4366</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Province_State  1/22/20  1/23/20  1/24/20  1/25/20  1/26/20  1/27/20  \\\n",
       "0         Alabama        0        0        0        0        0        0   \n",
       "1          Alaska        0        0        0        0        0        0   \n",
       "2  American Samoa        0        0        0        0        0        0   \n",
       "3         Arizona        0        0        0        0        1        1   \n",
       "4        Arkansas        0        0        0        0        0        0   \n",
       "\n",
       "   1/28/20  1/29/20  1/30/20  ...  5/7/20  5/8/20  5/9/20  5/10/20  5/11/20  \\\n",
       "0        0        0        0  ...    9046    9385    9668     9889    10164   \n",
       "1        0        0        0  ...     374     377     378      379      379   \n",
       "2        0        0        0  ...       0       0       0        0        0   \n",
       "3        1        1        1  ...    9945   10526   10960    11119    11383   \n",
       "4        0        0        0  ...    3703    3747    3747     4012     4043   \n",
       "\n",
       "   5/12/20  5/13/20  5/14/20           state  state_abb  \n",
       "0    10464    10700    11101         Alabama         AL  \n",
       "1      383      383      383          Alaska         AK  \n",
       "2        0        0        0  American Samoa        NaN  \n",
       "3    11736    12216    12674         Arizona         AZ  \n",
       "4     4164     4236     4366        Arkansas         AR  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from settings import states_full_dic\n",
    "df_date = df_states.drop(columns=['UID', 'code3', 'FIPS', 'Lat', 'Long_'])\n",
    "df_date['state'] = df_states['Province_State']\n",
    "df_date['state_abb'] = df_date['state'].apply(lambda x: states_full_dic[x] if x in states_full_dic else np.nan)\n",
    "df_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58 entries, 0 to 57\n",
      "Columns: 118 entries, Province_State to tweets_count\n",
      "dtypes: int64(115), object(3)\n",
      "memory usage: 53.6+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets_count = Counter(df['state'])\n",
    "df_date['tweets_count'] = df_date['state'].apply(lambda x: tweets_count[x])\n",
    "df_date.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58 entries, 0 to 57\n",
      "Columns: 118 entries, Province_State to tweets_count\n",
      "dtypes: int64(115), object(3)\n",
      "memory usage: 53.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_date.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_date = '5/8/20'\n",
    "total_cases = df_date['tweets_count'].sum()\n",
    "total_tweets = df_date[cases_date].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Correlation of total tweets and cases in USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'2/29/20': 1029372, '2/28/20': 641168, '3/03/20': 395178, '3/04/20': 375084, '3/01/20': 353729, '2/27/20': 270173, '2/26/20': 222188, '1/30/20': 196901, '1/31/20': 182578, '1/29/20': 178279, '2/10/20': 175686, '2/17/20': 168664, '2/11/20': 166505, '2/07/20': 160376, '2/12/20': 156682, '2/21/20': 154354, '2/19/20': 151048, '2/09/20': 138524, '2/13/20': 132946, '4/07/20': 130346, '4/01/20': 129156, '4/23/20': 127106, '4/08/20': 125361, '5/06/20': 124662, '4/22/20': 124617, '2/24/20': 123910, '4/02/20': 123692, '2/15/20': 123294, '5/05/20': 122299, '4/20/20': 121636, '4/06/20': 120511, '4/04/20': 119574, '4/09/20': 119297, '5/07/20': 118802, '2/25/20': 118109, '4/16/20': 118077, '4/21/20': 117762, '2/05/20': 117392, '3/06/20': 116903, '4/05/20': 116670, '4/24/20': 116357, '4/03/20': 115863, '5/04/20': 115686, '4/15/20': 115107, '4/25/20': 114863, '3/07/20': 114750, '2/20/20': 113409, '4/10/20': 113206, '4/29/20': 112606, '5/03/20': 111901, '3/30/20': 111496, '4/19/20': 111293, '3/20/20': 110664, '4/14/20': 110527, '4/28/20': 109474, '4/27/20': 108664, '1/26/20': 108192, '4/13/20': 107838, '4/26/20': 106957, '2/03/20': 106798, '4/18/20': 106740, '4/11/20': 105718, '3/08/20': 105454, '2/02/20': 105160, '1/28/20': 104838, '3/29/20': 103932, '3/31/20': 103461, '3/25/20': 103320, '5/02/20': 101975, '1/27/20': 101503, '4/30/20': 100803, '2/08/20': 100036, '5/08/20': 99730, '3/13/20': 98685, '2/18/20': 98328, '3/11/20': 97961, '4/12/20': 97693, '5/01/20': 96653, '2/16/20': 95478, '4/17/20': 94996, '2/04/20': 93780, '2/14/20': 92476, '3/02/20': 89226, '2/06/20': 87851, '3/17/20': 86748, '3/16/20': 84995, '3/24/20': 84878, '1/25/20': 84869, '3/14/20': 84046, '3/09/20': 83622, '3/05/20': 82934, '3/28/20': 82468, '3/27/20': 81319, '3/26/20': 78537, '3/23/20': 76628, '1/24/20': 74806, '3/22/20': 73966, '3/19/20': 72452, '3/21/20': 72309, '3/18/20': 72240, '3/12/20': 70756, '3/15/20': 68942, '2/22/20': 68925, '3/10/20': 63746, '2/01/20': 58263, '1/23/20': 24718, '1/22/20': 5070})\n",
      "['1/22/20', '1/23/20', '1/24/20', '1/25/20', '1/26/20', '1/27/20', '1/28/20', '1/29/20', '1/30/20', '1/31/20', '2/01/20', '2/02/20', '2/03/20', '2/04/20', '2/05/20', '2/06/20', '2/07/20', '2/08/20', '2/09/20', '2/10/20', '2/11/20', '2/12/20', '2/13/20', '2/14/20', '2/15/20', '2/16/20', '2/17/20', '2/18/20', '2/19/20', '2/20/20', '2/21/20', '2/22/20', '2/24/20', '2/25/20', '2/26/20', '2/27/20', '2/28/20', '2/29/20', '3/01/20', '3/02/20', '3/03/20', '3/04/20', '3/05/20', '3/06/20', '3/07/20', '3/08/20', '3/09/20', '3/10/20', '3/11/20', '3/12/20', '3/13/20', '3/14/20', '3/15/20', '3/16/20', '3/17/20', '3/18/20', '3/19/20', '3/20/20', '3/21/20', '3/22/20', '3/23/20', '3/24/20', '3/25/20', '3/26/20', '3/27/20', '3/28/20', '3/29/20', '3/30/20', '3/31/20', '4/01/20', '4/02/20', '4/03/20', '4/04/20', '4/05/20', '4/06/20', '4/07/20', '4/08/20', '4/09/20', '4/10/20', '4/11/20', '4/12/20', '4/13/20', '4/14/20', '4/15/20', '4/16/20', '4/17/20', '4/18/20', '4/19/20', '4/20/20', '4/21/20', '4/22/20', '4/23/20', '4/24/20', '4/25/20', '4/26/20', '4/27/20', '4/28/20', '4/29/20', '4/30/20', '5/01/20', '5/02/20', '5/03/20', '5/04/20', '5/05/20', '5/06/20', '5/07/20', '5/08/20']\n"
     ]
    }
   ],
   "source": [
    "tweets_date_daily = Counter(df['date'])\n",
    "# drop date of 1/21/20\n",
    "tweets_date_daily.pop(\"1/21/20\", None)\n",
    "date_order = sorted(tweets_date_daily)\n",
    "# name format\n",
    "for i in range(len(date_order)):\n",
    "    x = str(date_order[i]).split('/')\n",
    "    if len(x) > 1:\n",
    "        if len(x[1]) == 1:\n",
    "            x[1] = '0' + x[1]\n",
    "            tweets_date_daily['/'.join(x)] = tweets_date_daily.pop(date_order[i])\n",
    "print(tweets_date_daily)\n",
    "date_order = sorted(tweets_date_daily)\n",
    "print(date_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Province_State', '1/22/20', '1/23/20', '1/24/20', '1/25/20', '1/26/20', '1/27/20', '1/28/20', '1/29/20', '1/30/20', '1/31/20', '2/01/20', '2/02/20', '2/03/20', '2/04/20', '2/05/20', '2/06/20', '2/07/20', '2/08/20', '2/09/20', '2/10/20', '2/11/20', '2/12/20', '2/13/20', '2/14/20', '2/15/20', '2/16/20', '2/17/20', '2/18/20', '2/19/20', '2/20/20', '2/21/20', '2/22/20', '2/23/20', '2/24/20', '2/25/20', '2/26/20', '2/27/20', '2/28/20', '2/29/20', '3/01/20', '3/02/20', '3/03/20', '3/04/20', '3/05/20', '3/06/20', '3/07/20', '3/08/20', '3/09/20', '3/10/20', '3/11/20', '3/12/20', '3/13/20', '3/14/20', '3/15/20', '3/16/20', '3/17/20', '3/18/20', '3/19/20', '3/20/20', '3/21/20', '3/22/20', '3/23/20', '3/24/20', '3/25/20', '3/26/20', '3/27/20', '3/28/20', '3/29/20', '3/30/20', '3/31/20', '4/01/20', '4/02/20', '4/03/20', '4/04/20', '4/05/20', '4/06/20', '4/07/20', '4/08/20', '4/09/20', '4/10/20', '4/11/20', '4/12/20', '4/13/20', '4/14/20', '4/15/20', '4/16/20', '4/17/20', '4/18/20', '4/19/20', '4/20/20', '4/21/20', '4/22/20', '4/23/20', '4/24/20', '4/25/20', '4/26/20', '4/27/20', '4/28/20', '4/29/20', '4/30/20', '5/01/20', '5/02/20', '5/03/20', '5/04/20', '5/05/20', '5/06/20', '5/07/20', '5/08/20', '5/09/20', '5/10/20', '5/11/20', '5/12/20', '5/13/20', '5/14/20', 'state', 'state_abb', 'tweets_count']\n"
     ]
    }
   ],
   "source": [
    "# match date format\n",
    "c = list(df_date.columns)\n",
    "c_new = list(df_date.columns)\n",
    "for i in range(len(c)):\n",
    "    x = str(c[i]).split('/')\n",
    "    if len(x) > 1:\n",
    "        if len(x[1]) == 1:\n",
    "            x[1] = '0' + x[1]\n",
    "            c_new[i] = '/'.join(x) \n",
    "df_date.rename(columns = {c[i]:c_new[i] for i in range(len(c))}, inplace = True) \n",
    "cd = df_date.columns\n",
    "print([i for i in cd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets_data: \n",
      "{'1/22/20': 5070, '1/23/20': 29788, '1/24/20': 104594, '1/25/20': 189463, '1/26/20': 297655, '1/27/20': 399158, '1/28/20': 503996, '1/29/20': 682275, '1/30/20': 879176, '1/31/20': 1061754, '2/01/20': 1120017, '2/02/20': 1225177, '2/03/20': 1331975, '2/04/20': 1425755, '2/05/20': 1543147, '2/06/20': 1630998, '2/07/20': 1791374, '2/08/20': 1891410, '2/09/20': 2029934, '2/10/20': 2205620, '2/11/20': 2372125, '2/12/20': 2528807, '2/13/20': 2661753, '2/14/20': 2754229, '2/15/20': 2877523, '2/16/20': 2973001, '2/17/20': 3141665, '2/18/20': 3239993, '2/19/20': 3391041, '2/20/20': 3504450, '2/21/20': 3658804, '2/22/20': 3727729, '2/24/20': 3851639, '2/25/20': 3969748, '2/26/20': 4191936, '2/27/20': 4462109, '2/28/20': 5103277, '2/29/20': 6132649, '3/01/20': 6486378, '3/02/20': 6575604, '3/03/20': 6970782, '3/04/20': 7345866, '3/05/20': 7428800, '3/06/20': 7545703, '3/07/20': 7660453, '3/08/20': 7765907, '3/09/20': 7849529, '3/10/20': 7913275, '3/11/20': 8011236, '3/12/20': 8081992, '3/13/20': 8180677, '3/14/20': 8264723, '3/15/20': 8333665, '3/16/20': 8418660, '3/17/20': 8505408, '3/18/20': 8577648, '3/19/20': 8650100, '3/20/20': 8760764, '3/21/20': 8833073, '3/22/20': 8907039, '3/23/20': 8983667, '3/24/20': 9068545, '3/25/20': 9171865, '3/26/20': 9250402, '3/27/20': 9331721, '3/28/20': 9414189, '3/29/20': 9518121, '3/30/20': 9629617, '3/31/20': 9733078, '4/01/20': 9862234, '4/02/20': 9985926, '4/03/20': 10101789, '4/04/20': 10221363, '4/05/20': 10338033, '4/06/20': 10458544, '4/07/20': 10588890, '4/08/20': 10714251, '4/09/20': 10833548, '4/10/20': 10946754, '4/11/20': 11052472, '4/12/20': 11150165, '4/13/20': 11258003, '4/14/20': 11368530, '4/15/20': 11483637, '4/16/20': 11601714, '4/17/20': 11696710, '4/18/20': 11803450, '4/19/20': 11914743, '4/20/20': 12036379, '4/21/20': 12154141, '4/22/20': 12278758, '4/23/20': 12405864, '4/24/20': 12522221, '4/25/20': 12637084, '4/26/20': 12744041, '4/27/20': 12852705, '4/28/20': 12962179, '4/29/20': 13074785, '4/30/20': 13175588, '5/01/20': 13272241, '5/02/20': 13374216, '5/03/20': 13486117, '5/04/20': 13601803, '5/05/20': 13724102, '5/06/20': 13848764, '5/07/20': 13967566, '5/08/20': 14067296}\n",
      "cases_date: \n",
      "{'1/22/20': 1, '1/23/20': 1, '1/24/20': 2, '1/25/20': 2, '1/26/20': 5, '1/27/20': 5, '1/28/20': 5, '1/29/20': 5, '1/30/20': 5, '1/31/20': 7, '2/01/20': 8, '2/02/20': 8, '2/03/20': 11, '2/04/20': 11, '2/05/20': 11, '2/06/20': 11, '2/07/20': 11, '2/08/20': 11, '2/09/20': 11, '2/10/20': 11, '2/11/20': 12, '2/12/20': 12, '2/13/20': 13, '2/14/20': 13, '2/15/20': 13, '2/16/20': 13, '2/17/20': 13, '2/18/20': 13, '2/19/20': 13, '2/20/20': 13, '2/21/20': 15, '2/22/20': 15, '2/24/20': 15, '2/25/20': 15, '2/26/20': 15, '2/27/20': 16, '2/28/20': 16, '2/29/20': 24, '3/01/20': 30, '3/02/20': 53, '3/03/20': 73, '3/04/20': 104, '3/05/20': 172, '3/06/20': 217, '3/07/20': 336, '3/08/20': 450, '3/09/20': 514, '3/10/20': 708, '3/11/20': 1105, '3/12/20': 1557, '3/13/20': 2147, '3/14/20': 2857, '3/15/20': 2918, '3/16/20': 4307, '3/17/20': 6096, '3/18/20': 8873, '3/19/20': 14094, '3/20/20': 19403, '3/21/20': 25725, '3/22/20': 33634, '3/23/20': 43663, '3/24/20': 53736, '3/25/20': 65778, '3/26/20': 83836, '3/27/20': 101657, '3/28/20': 121465, '3/29/20': 140909, '3/30/20': 161831, '3/31/20': 188172, '4/01/20': 213242, '4/02/20': 243622, '4/03/20': 275367, '4/04/20': 308650, '4/05/20': 336802, '4/06/20': 366317, '4/07/20': 397121, '4/08/20': 428654, '4/09/20': 462780, '4/10/20': 496535, '4/11/20': 526396, '4/12/20': 555313, '4/13/20': 580619, '4/14/20': 607670, '4/15/20': 636350, '4/16/20': 667592, '4/17/20': 699706, '4/18/20': 727959, '4/19/20': 754376, '4/20/20': 779682, '4/21/20': 807023, '4/22/20': 835150, '4/23/20': 869170, '4/24/20': 905358, '4/25/20': 938154, '4/26/20': 965785, '4/27/20': 988197, '4/28/20': 1012582, '4/29/20': 1039909, '4/30/20': 1069424, '5/01/20': 1103461, '5/02/20': 1132539, '5/03/20': 1158040, '5/04/20': 1180375, '5/05/20': 1204351, '5/06/20': 1229331, '5/07/20': 1257023, '5/08/20': 1283929}\n"
     ]
    }
   ],
   "source": [
    "# accumulate tweets data\n",
    "tweets_date = {}\n",
    "for i in range(len(date_order)):\n",
    "    if i == 0:\n",
    "        tweets_date[date_order[i]] = tweets_date_daily[date_order[i]]\n",
    "    else:\n",
    "        tweets_date[date_order[i]] = tweets_date_daily[date_order[i]] + tweets_date[date_order[i-1]]   \n",
    "print(\"tweets_data: \")\n",
    "print(tweets_date)\n",
    "# total cases\n",
    "cases_date = {key:df_date[key].sum() for key in tweets_date}\n",
    "print(\"cases_date: \")\n",
    "print(cases_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_percentage(key, sentiment):\n",
    "    return (df[(df['date'] == key)]['sentiment']==sentiment).sum()/(df[(df['date'] == key)]['sentiment']).count()\n",
    "# positive sentiment count\n",
    "sentiment_pos =  {key:sentiment_percentage(key, 'positive') for key in date_order}\n",
    "# negative sentiment count\n",
    "sentiment_neg =  {key:sentiment_percentage(key, 'negative') for key in date_order}\n",
    "# neutral sentiment count\n",
    "sentiment_neut =  {key:sentiment_percentage(key, 'neutral') for key in date_order}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweets</th>\n",
       "      <th>cases</th>\n",
       "      <th>sentiment_pos</th>\n",
       "      <th>sentiment_neg</th>\n",
       "      <th>sentiment_neut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/22/20</td>\n",
       "      <td>5070</td>\n",
       "      <td>1</td>\n",
       "      <td>0.338659</td>\n",
       "      <td>0.390927</td>\n",
       "      <td>0.270414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/23/20</td>\n",
       "      <td>29788</td>\n",
       "      <td>1</td>\n",
       "      <td>0.251032</td>\n",
       "      <td>0.515171</td>\n",
       "      <td>0.233797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/24/20</td>\n",
       "      <td>104594</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344865</td>\n",
       "      <td>0.337232</td>\n",
       "      <td>0.317902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/25/20</td>\n",
       "      <td>189463</td>\n",
       "      <td>2</td>\n",
       "      <td>0.316959</td>\n",
       "      <td>0.373682</td>\n",
       "      <td>0.309359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/26/20</td>\n",
       "      <td>297655</td>\n",
       "      <td>5</td>\n",
       "      <td>0.278588</td>\n",
       "      <td>0.368974</td>\n",
       "      <td>0.352438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      date  tweets  cases  sentiment_pos  sentiment_neg  sentiment_neut\n",
       "0  1/22/20    5070      1       0.338659       0.390927        0.270414\n",
       "1  1/23/20   29788      1       0.251032       0.515171        0.233797\n",
       "2  1/24/20  104594      2       0.344865       0.337232        0.317902\n",
       "3  1/25/20  189463      2       0.316959       0.373682        0.309359\n",
       "4  1/26/20  297655      5       0.278588       0.368974        0.352438"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "    'date':date_order, \n",
    "    'tweets':[tweets_date[i] for i in date_order], \n",
    "    'cases':[cases_date[i] for i in date_order],\n",
    "    'sentiment_pos':[sentiment_pos[i] for i in date_order],\n",
    "    'sentiment_neg':[sentiment_neg[i] for i in date_order],\n",
    "    'sentiment_neut':[sentiment_neut[i] for i in date_order],\n",
    "}\n",
    "df_tweets_cases = pd.DataFrame(data=d)\n",
    "df_tweets_cases.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_extract(single_state):\n",
    "    df_single_state = df[df['state']==single_state]\n",
    "    df_date_single_state = df_date[df_date['Province_State']==single_state]\n",
    "    tweets_count_single_state = Counter(df_single_state['state'])\n",
    "    df_date_single_state['tweets_count'] = df_date_single_state['state'].apply(lambda x: tweets_count_single_state[x])\n",
    "\n",
    "    tweets_date_daily_single_state = Counter(df_single_state['date'])\n",
    "    # drop date of 1/21/20\n",
    "    tweets_date_daily_single_state.pop(\"1/21/20\", None)\n",
    "    date_order_single_state = sorted(tweets_date_daily_single_state)\n",
    "\n",
    "    # date name format\n",
    "    for i in range(len(date_order_single_state)):\n",
    "        x = str(date_order_single_state[i]).split('/')\n",
    "        if len(x) > 1:\n",
    "            if len(x[1]) == 1:\n",
    "                x[1] = '0' + x[1]\n",
    "                tweets_date_daily_single_state['/'.join(x)] = tweets_date_daily_single_state.pop(date_order_single_state[i])\n",
    "    # print(tweets_date_daily_single_state)\n",
    "    date_order_single_state = sorted(tweets_date_daily_single_state)\n",
    "\n",
    "    def sentiment_percentage(key, sentiment):\n",
    "        return (df_single_state[(df_single_state['date'] == key)]['sentiment']==sentiment).sum()/(df_single_state[(df_single_state['date'] == key)]['sentiment']).count()\n",
    "    # positive sentiment count\n",
    "    sentiment_pos_single_state =  {key:sentiment_percentage(key, 'positive') for key in date_order_single_state}\n",
    "    # negative sentiment count\n",
    "    sentiment_neg_single_state =  {key:sentiment_percentage(key, 'negative') for key in date_order_single_state}\n",
    "    # neutral sentiment count\n",
    "    sentiment_neut_single_state =  {key:sentiment_percentage(key, 'neutral') for key in date_order_single_state}\n",
    "\n",
    "\n",
    "    # accumulate tweets data\n",
    "    tweets_date_single_state = {}\n",
    "    for i in range(len(date_order_single_state)):\n",
    "        if i == 0:\n",
    "            tweets_date_single_state[date_order_single_state[i]] = tweets_date_daily_single_state[date_order_single_state[i]]\n",
    "        else:\n",
    "            tweets_date_single_state[date_order_single_state[i]] = tweets_date_daily_single_state[date_order_single_state[i]] + tweets_date_single_state[date_order_single_state[i-1]]   \n",
    "    # total cases\n",
    "    cases_date_single_state = {key:df_date_single_state[key].sum() for key in tweets_date_single_state}\n",
    "    \n",
    "    \n",
    "    tweet = [tweets_date_single_state[i] for i in date_order_single_state] \n",
    "    case = [cases_date_single_state[i] for i in date_order_single_state]\n",
    "#     'sentiment_pos':[sentiment_pos_single_state[i] for i in date_order_single_state],\n",
    "#     'sentiment_neg':[sentiment_neg_single_state[i] for i in date_order_single_state],\n",
    "#     'sentiment_neut':[sentiment_neut_single_state[i] for i in date_order_single_state],\n",
    "#     sentiment = [sentiment_pos_single_state[i]-sentiment_neg_single_state[i] for i in date_order_single_state]\n",
    "    sentiment = [sentiment_pos_single_state[i] for i in date_order_single_state]\n",
    "    \n",
    "    return tweet, case, sentiment\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>case_us</th>\n",
       "      <th>tweet_us</th>\n",
       "      <th>sentiment_us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/22/20</td>\n",
       "      <td>1</td>\n",
       "      <td>5070</td>\n",
       "      <td>-0.052268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/23/20</td>\n",
       "      <td>1</td>\n",
       "      <td>29788</td>\n",
       "      <td>-0.264139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/24/20</td>\n",
       "      <td>2</td>\n",
       "      <td>104594</td>\n",
       "      <td>0.007633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/25/20</td>\n",
       "      <td>2</td>\n",
       "      <td>189463</td>\n",
       "      <td>-0.056723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/26/20</td>\n",
       "      <td>5</td>\n",
       "      <td>297655</td>\n",
       "      <td>-0.090386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>5/04/20</td>\n",
       "      <td>1180375</td>\n",
       "      <td>13601803</td>\n",
       "      <td>-0.048433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>5/05/20</td>\n",
       "      <td>1204351</td>\n",
       "      <td>13724102</td>\n",
       "      <td>-0.034457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>5/06/20</td>\n",
       "      <td>1229331</td>\n",
       "      <td>13848764</td>\n",
       "      <td>-0.044504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>5/07/20</td>\n",
       "      <td>1257023</td>\n",
       "      <td>13967566</td>\n",
       "      <td>-0.020378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>5/08/20</td>\n",
       "      <td>1283929</td>\n",
       "      <td>14067296</td>\n",
       "      <td>-0.011160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  case_us  tweet_us  sentiment_us\n",
       "0    1/22/20        1      5070     -0.052268\n",
       "1    1/23/20        1     29788     -0.264139\n",
       "2    1/24/20        2    104594      0.007633\n",
       "3    1/25/20        2    189463     -0.056723\n",
       "4    1/26/20        5    297655     -0.090386\n",
       "..       ...      ...       ...           ...\n",
       "102  5/04/20  1180375  13601803     -0.048433\n",
       "103  5/05/20  1204351  13724102     -0.034457\n",
       "104  5/06/20  1229331  13848764     -0.044504\n",
       "105  5/07/20  1257023  13967566     -0.020378\n",
       "106  5/08/20  1283929  14067296     -0.011160\n",
       "\n",
       "[107 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Organize dataset for us\n",
    "d_overall = {\n",
    "    'date':d['date'], \n",
    "    'case_us':d['cases'],\n",
    "    'tweet_us':d['tweets'], \n",
    "    'sentiment_us':[p-n for p, n in zip(d['sentiment_pos'], d['sentiment_neg'])]\n",
    "}\n",
    "df_overall = pd.DataFrame(data=d_overall)\n",
    "df_overall\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_full_dic = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    # 'American Samoa': 'AS',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    # 'Guam': 'GU',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    # 'Northern Mariana Islands':'MP',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    # 'Puerto Rico': 'PR',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    # 'Virgin Islands': 'VI',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing at state:  Alabama\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/allen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing at state:  Alaska\n",
      "Analyzing at state:  Arizona\n",
      "Analyzing at state:  Arkansas\n",
      "Analyzing at state:  California\n",
      "Analyzing at state:  Colorado\n",
      "Analyzing at state:  Connecticut\n",
      "Analyzing at state:  Delaware\n",
      "Analyzing at state:  District of Columbia\n",
      "Analyzing at state:  Florida\n",
      "Analyzing at state:  Georgia\n",
      "Analyzing at state:  Hawaii\n",
      "Analyzing at state:  Idaho\n",
      "Analyzing at state:  Illinois\n",
      "Analyzing at state:  Indiana\n",
      "Analyzing at state:  Iowa\n",
      "Analyzing at state:  Kansas\n",
      "Analyzing at state:  Kentucky\n",
      "Analyzing at state:  Louisiana\n",
      "Analyzing at state:  Maine\n",
      "Analyzing at state:  Maryland\n",
      "Analyzing at state:  Massachusetts\n",
      "Analyzing at state:  Michigan\n",
      "Analyzing at state:  Minnesota\n",
      "Analyzing at state:  Mississippi\n",
      "Analyzing at state:  Missouri\n",
      "Analyzing at state:  Montana\n",
      "Analyzing at state:  Nebraska\n",
      "Analyzing at state:  Nevada\n",
      "Analyzing at state:  New Hampshire\n",
      "Analyzing at state:  New Jersey\n",
      "Analyzing at state:  New Mexico\n",
      "Analyzing at state:  New York\n",
      "Analyzing at state:  North Carolina\n",
      "Analyzing at state:  North Dakota\n",
      "Analyzing at state:  Ohio\n",
      "Analyzing at state:  Oklahoma\n",
      "Analyzing at state:  Oregon\n",
      "Analyzing at state:  Pennsylvania\n",
      "Analyzing at state:  Rhode Island\n",
      "Analyzing at state:  South Carolina\n",
      "Analyzing at state:  South Dakota\n",
      "Analyzing at state:  Tennessee\n",
      "Analyzing at state:  Texas\n",
      "Analyzing at state:  Utah\n",
      "Analyzing at state:  Vermont\n",
      "Analyzing at state:  Virginia\n",
      "Analyzing at state:  Washington\n",
      "Analyzing at state:  West Virginia\n",
      "Analyzing at state:  Wisconsin\n",
      "Analyzing at state:  Wyoming\n"
     ]
    }
   ],
   "source": [
    "# dictionary of tweet, case, sentiment for each state\n",
    "df_tweets_all = dict()\n",
    "df_cases_all = dict()\n",
    "df_sentiment_all = dict()\n",
    "\n",
    "for single_state, single_state_abb in states_full_dic.items():\n",
    "    print(\"Analyzing at state: \", single_state)\n",
    "    tweet, case, sentiment = data_extract(single_state)\n",
    "    df_cases_all['case_%s'%single_state_abb] = case\n",
    "    df_tweets_all['tweet_%s'%single_state_abb] = tweet\n",
    "    df_sentiment_all['sentiment_%s'%single_state_abb] = sentiment\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "51\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "print(len(df_tweets_all))\n",
    "print(len(df_cases_all))\n",
    "print(len(df_sentiment_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, values in df_cases_all.items():\n",
    "    if len(values) == 0:\n",
    "        print(\"%s, %i \" % (key, len(values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_AL</th>\n",
       "      <th>case_AK</th>\n",
       "      <th>case_AZ</th>\n",
       "      <th>case_AR</th>\n",
       "      <th>case_CA</th>\n",
       "      <th>case_CO</th>\n",
       "      <th>case_CT</th>\n",
       "      <th>case_DE</th>\n",
       "      <th>case_DC</th>\n",
       "      <th>case_FL</th>\n",
       "      <th>...</th>\n",
       "      <th>sentiment_SD</th>\n",
       "      <th>sentiment_TN</th>\n",
       "      <th>sentiment_TX</th>\n",
       "      <th>sentiment_UT</th>\n",
       "      <th>sentiment_VT</th>\n",
       "      <th>sentiment_VA</th>\n",
       "      <th>sentiment_WA</th>\n",
       "      <th>sentiment_WV</th>\n",
       "      <th>sentiment_WI</th>\n",
       "      <th>sentiment_WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>0.297921</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>0.370130</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.283582</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182927</td>\n",
       "      <td>0.253669</td>\n",
       "      <td>0.251005</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.279935</td>\n",
       "      <td>0.274775</td>\n",
       "      <td>0.257426</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286885</td>\n",
       "      <td>0.322759</td>\n",
       "      <td>0.384396</td>\n",
       "      <td>0.339450</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.341695</td>\n",
       "      <td>0.344907</td>\n",
       "      <td>0.317690</td>\n",
       "      <td>0.293168</td>\n",
       "      <td>0.280255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.266850</td>\n",
       "      <td>0.328908</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.296499</td>\n",
       "      <td>0.304866</td>\n",
       "      <td>0.280702</td>\n",
       "      <td>0.291310</td>\n",
       "      <td>0.236111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.278638</td>\n",
       "      <td>0.271512</td>\n",
       "      <td>0.282692</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.273628</td>\n",
       "      <td>0.305022</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.247159</td>\n",
       "      <td>0.232558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>8112</td>\n",
       "      <td>370</td>\n",
       "      <td>8924</td>\n",
       "      <td>3491</td>\n",
       "      <td>55884</td>\n",
       "      <td>16918</td>\n",
       "      <td>29973</td>\n",
       "      <td>5288</td>\n",
       "      <td>5170</td>\n",
       "      <td>36897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422078</td>\n",
       "      <td>0.344294</td>\n",
       "      <td>0.339451</td>\n",
       "      <td>0.371560</td>\n",
       "      <td>0.312775</td>\n",
       "      <td>0.347455</td>\n",
       "      <td>0.367414</td>\n",
       "      <td>0.361798</td>\n",
       "      <td>0.334796</td>\n",
       "      <td>0.263514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>8437</td>\n",
       "      <td>371</td>\n",
       "      <td>9305</td>\n",
       "      <td>3525</td>\n",
       "      <td>58456</td>\n",
       "      <td>17367</td>\n",
       "      <td>30621</td>\n",
       "      <td>5371</td>\n",
       "      <td>5322</td>\n",
       "      <td>37439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.370817</td>\n",
       "      <td>0.340450</td>\n",
       "      <td>0.356223</td>\n",
       "      <td>0.410853</td>\n",
       "      <td>0.360413</td>\n",
       "      <td>0.380318</td>\n",
       "      <td>0.378495</td>\n",
       "      <td>0.367030</td>\n",
       "      <td>0.386207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>8691</td>\n",
       "      <td>372</td>\n",
       "      <td>9707</td>\n",
       "      <td>3611</td>\n",
       "      <td>60616</td>\n",
       "      <td>17832</td>\n",
       "      <td>30995</td>\n",
       "      <td>5778</td>\n",
       "      <td>5461</td>\n",
       "      <td>38002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.337012</td>\n",
       "      <td>0.349814</td>\n",
       "      <td>0.376359</td>\n",
       "      <td>0.330855</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.384506</td>\n",
       "      <td>0.322785</td>\n",
       "      <td>0.369231</td>\n",
       "      <td>0.344828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>9046</td>\n",
       "      <td>374</td>\n",
       "      <td>9945</td>\n",
       "      <td>3703</td>\n",
       "      <td>62148</td>\n",
       "      <td>18370</td>\n",
       "      <td>31784</td>\n",
       "      <td>5939</td>\n",
       "      <td>5654</td>\n",
       "      <td>38828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362963</td>\n",
       "      <td>0.382710</td>\n",
       "      <td>0.353646</td>\n",
       "      <td>0.410891</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.379421</td>\n",
       "      <td>0.392800</td>\n",
       "      <td>0.381818</td>\n",
       "      <td>0.374449</td>\n",
       "      <td>0.461078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>9385</td>\n",
       "      <td>377</td>\n",
       "      <td>10526</td>\n",
       "      <td>3747</td>\n",
       "      <td>63779</td>\n",
       "      <td>18827</td>\n",
       "      <td>32411</td>\n",
       "      <td>6111</td>\n",
       "      <td>5899</td>\n",
       "      <td>39199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>0.364507</td>\n",
       "      <td>0.353944</td>\n",
       "      <td>0.418848</td>\n",
       "      <td>0.381579</td>\n",
       "      <td>0.391559</td>\n",
       "      <td>0.383536</td>\n",
       "      <td>0.389728</td>\n",
       "      <td>0.378561</td>\n",
       "      <td>0.295455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     case_AL  case_AK  case_AZ  case_AR  case_CA  case_CO  case_CT  case_DE  \\\n",
       "0          0        0        0        0        0        0        0        0   \n",
       "1          0        0        0        0        0        0        0        0   \n",
       "2          0        0        0        0        0        0        0        0   \n",
       "3          0        0        0        0        0        0        0        0   \n",
       "4          0        0        1        0        2        0        0        0   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "102     8112      370     8924     3491    55884    16918    29973     5288   \n",
       "103     8437      371     9305     3525    58456    17367    30621     5371   \n",
       "104     8691      372     9707     3611    60616    17832    30995     5778   \n",
       "105     9046      374     9945     3703    62148    18370    31784     5939   \n",
       "106     9385      377    10526     3747    63779    18827    32411     6111   \n",
       "\n",
       "     case_DC  case_FL  ...  sentiment_SD  sentiment_TN  sentiment_TX  \\\n",
       "0          0        0  ...      0.222222      0.317073      0.297921   \n",
       "1          0        0  ...      0.182927      0.253669      0.251005   \n",
       "2          0        0  ...      0.286885      0.322759      0.384396   \n",
       "3          0        0  ...      0.257143      0.266850      0.328908   \n",
       "4          0        0  ...      0.245902      0.278638      0.271512   \n",
       "..       ...      ...  ...           ...           ...           ...   \n",
       "102     5170    36897  ...      0.422078      0.344294      0.339451   \n",
       "103     5322    37439  ...      0.324324      0.370817      0.340450   \n",
       "104     5461    38002  ...      0.377778      0.337012      0.349814   \n",
       "105     5654    38828  ...      0.362963      0.382710      0.353646   \n",
       "106     5899    39199  ...      0.376000      0.364507      0.353944   \n",
       "\n",
       "     sentiment_UT  sentiment_VT  sentiment_VA  sentiment_WA  sentiment_WV  \\\n",
       "0        0.277778      0.285714      0.376000      0.370130      0.230769   \n",
       "1        0.278571      0.200000      0.279935      0.274775      0.257426   \n",
       "2        0.339450      0.309091      0.341695      0.344907      0.317690   \n",
       "3        0.320000      0.397959      0.296499      0.304866      0.280702   \n",
       "4        0.282692      0.375000      0.273628      0.305022      0.229167   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "102      0.371560      0.312775      0.347455      0.367414      0.361798   \n",
       "103      0.356223      0.410853      0.360413      0.380318      0.378495   \n",
       "104      0.376359      0.330855      0.358974      0.384506      0.322785   \n",
       "105      0.410891      0.380952      0.379421      0.392800      0.381818   \n",
       "106      0.418848      0.381579      0.391559      0.383536      0.389728   \n",
       "\n",
       "     sentiment_WI  sentiment_WY  \n",
       "0        0.283582      0.000000  \n",
       "1        0.190476      0.333333  \n",
       "2        0.293168      0.280255  \n",
       "3        0.291310      0.236111  \n",
       "4        0.247159      0.232558  \n",
       "..            ...           ...  \n",
       "102      0.334796      0.263514  \n",
       "103      0.367030      0.386207  \n",
       "104      0.369231      0.344828  \n",
       "105      0.374449      0.461078  \n",
       "106      0.378561      0.295455  \n",
       "\n",
       "[107 rows x 153 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_case_overall = pd.DataFrame(data=df_cases_all)\n",
    "df_tweet_overall = pd.DataFrame(data=df_tweets_all)\n",
    "df_sentiment_overall = pd.DataFrame(data=df_sentiment_all)\n",
    "\n",
    "df_state_overall = pd.concat([df_case_overall, \n",
    "                              df_tweet_overall.reindex(df_case_overall.index), \n",
    "                              df_sentiment_overall.reindex(df_case_overall.index)], \n",
    "                              axis=1)\n",
    "df_state_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>case_us</th>\n",
       "      <th>tweet_us</th>\n",
       "      <th>sentiment_us</th>\n",
       "      <th>case_AL</th>\n",
       "      <th>case_AK</th>\n",
       "      <th>case_AZ</th>\n",
       "      <th>case_AR</th>\n",
       "      <th>case_CA</th>\n",
       "      <th>case_CO</th>\n",
       "      <th>...</th>\n",
       "      <th>sentiment_SD</th>\n",
       "      <th>sentiment_TN</th>\n",
       "      <th>sentiment_TX</th>\n",
       "      <th>sentiment_UT</th>\n",
       "      <th>sentiment_VT</th>\n",
       "      <th>sentiment_VA</th>\n",
       "      <th>sentiment_WA</th>\n",
       "      <th>sentiment_WV</th>\n",
       "      <th>sentiment_WI</th>\n",
       "      <th>sentiment_WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/22/20</td>\n",
       "      <td>1</td>\n",
       "      <td>5070</td>\n",
       "      <td>-0.052268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>0.297921</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>0.370130</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.283582</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/23/20</td>\n",
       "      <td>1</td>\n",
       "      <td>29788</td>\n",
       "      <td>-0.264139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182927</td>\n",
       "      <td>0.253669</td>\n",
       "      <td>0.251005</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.279935</td>\n",
       "      <td>0.274775</td>\n",
       "      <td>0.257426</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/24/20</td>\n",
       "      <td>2</td>\n",
       "      <td>104594</td>\n",
       "      <td>0.007633</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286885</td>\n",
       "      <td>0.322759</td>\n",
       "      <td>0.384396</td>\n",
       "      <td>0.339450</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.341695</td>\n",
       "      <td>0.344907</td>\n",
       "      <td>0.317690</td>\n",
       "      <td>0.293168</td>\n",
       "      <td>0.280255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/25/20</td>\n",
       "      <td>2</td>\n",
       "      <td>189463</td>\n",
       "      <td>-0.056723</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.266850</td>\n",
       "      <td>0.328908</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.296499</td>\n",
       "      <td>0.304866</td>\n",
       "      <td>0.280702</td>\n",
       "      <td>0.291310</td>\n",
       "      <td>0.236111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/26/20</td>\n",
       "      <td>5</td>\n",
       "      <td>297655</td>\n",
       "      <td>-0.090386</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.278638</td>\n",
       "      <td>0.271512</td>\n",
       "      <td>0.282692</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.273628</td>\n",
       "      <td>0.305022</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.247159</td>\n",
       "      <td>0.232558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>5/04/20</td>\n",
       "      <td>1180375</td>\n",
       "      <td>13601803</td>\n",
       "      <td>-0.048433</td>\n",
       "      <td>8112</td>\n",
       "      <td>370</td>\n",
       "      <td>8924</td>\n",
       "      <td>3491</td>\n",
       "      <td>55884</td>\n",
       "      <td>16918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422078</td>\n",
       "      <td>0.344294</td>\n",
       "      <td>0.339451</td>\n",
       "      <td>0.371560</td>\n",
       "      <td>0.312775</td>\n",
       "      <td>0.347455</td>\n",
       "      <td>0.367414</td>\n",
       "      <td>0.361798</td>\n",
       "      <td>0.334796</td>\n",
       "      <td>0.263514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>5/05/20</td>\n",
       "      <td>1204351</td>\n",
       "      <td>13724102</td>\n",
       "      <td>-0.034457</td>\n",
       "      <td>8437</td>\n",
       "      <td>371</td>\n",
       "      <td>9305</td>\n",
       "      <td>3525</td>\n",
       "      <td>58456</td>\n",
       "      <td>17367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.370817</td>\n",
       "      <td>0.340450</td>\n",
       "      <td>0.356223</td>\n",
       "      <td>0.410853</td>\n",
       "      <td>0.360413</td>\n",
       "      <td>0.380318</td>\n",
       "      <td>0.378495</td>\n",
       "      <td>0.367030</td>\n",
       "      <td>0.386207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>5/06/20</td>\n",
       "      <td>1229331</td>\n",
       "      <td>13848764</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>8691</td>\n",
       "      <td>372</td>\n",
       "      <td>9707</td>\n",
       "      <td>3611</td>\n",
       "      <td>60616</td>\n",
       "      <td>17832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.337012</td>\n",
       "      <td>0.349814</td>\n",
       "      <td>0.376359</td>\n",
       "      <td>0.330855</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.384506</td>\n",
       "      <td>0.322785</td>\n",
       "      <td>0.369231</td>\n",
       "      <td>0.344828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>5/07/20</td>\n",
       "      <td>1257023</td>\n",
       "      <td>13967566</td>\n",
       "      <td>-0.020378</td>\n",
       "      <td>9046</td>\n",
       "      <td>374</td>\n",
       "      <td>9945</td>\n",
       "      <td>3703</td>\n",
       "      <td>62148</td>\n",
       "      <td>18370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362963</td>\n",
       "      <td>0.382710</td>\n",
       "      <td>0.353646</td>\n",
       "      <td>0.410891</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.379421</td>\n",
       "      <td>0.392800</td>\n",
       "      <td>0.381818</td>\n",
       "      <td>0.374449</td>\n",
       "      <td>0.461078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>5/08/20</td>\n",
       "      <td>1283929</td>\n",
       "      <td>14067296</td>\n",
       "      <td>-0.011160</td>\n",
       "      <td>9385</td>\n",
       "      <td>377</td>\n",
       "      <td>10526</td>\n",
       "      <td>3747</td>\n",
       "      <td>63779</td>\n",
       "      <td>18827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>0.364507</td>\n",
       "      <td>0.353944</td>\n",
       "      <td>0.418848</td>\n",
       "      <td>0.381579</td>\n",
       "      <td>0.391559</td>\n",
       "      <td>0.383536</td>\n",
       "      <td>0.389728</td>\n",
       "      <td>0.378561</td>\n",
       "      <td>0.295455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  case_us  tweet_us  sentiment_us  case_AL  case_AK  case_AZ  \\\n",
       "0    1/22/20        1      5070     -0.052268        0        0        0   \n",
       "1    1/23/20        1     29788     -0.264139        0        0        0   \n",
       "2    1/24/20        2    104594      0.007633        0        0        0   \n",
       "3    1/25/20        2    189463     -0.056723        0        0        0   \n",
       "4    1/26/20        5    297655     -0.090386        0        0        1   \n",
       "..       ...      ...       ...           ...      ...      ...      ...   \n",
       "102  5/04/20  1180375  13601803     -0.048433     8112      370     8924   \n",
       "103  5/05/20  1204351  13724102     -0.034457     8437      371     9305   \n",
       "104  5/06/20  1229331  13848764     -0.044504     8691      372     9707   \n",
       "105  5/07/20  1257023  13967566     -0.020378     9046      374     9945   \n",
       "106  5/08/20  1283929  14067296     -0.011160     9385      377    10526   \n",
       "\n",
       "     case_AR  case_CA  case_CO  ...  sentiment_SD  sentiment_TN  sentiment_TX  \\\n",
       "0          0        0        0  ...      0.222222      0.317073      0.297921   \n",
       "1          0        0        0  ...      0.182927      0.253669      0.251005   \n",
       "2          0        0        0  ...      0.286885      0.322759      0.384396   \n",
       "3          0        0        0  ...      0.257143      0.266850      0.328908   \n",
       "4          0        2        0  ...      0.245902      0.278638      0.271512   \n",
       "..       ...      ...      ...  ...           ...           ...           ...   \n",
       "102     3491    55884    16918  ...      0.422078      0.344294      0.339451   \n",
       "103     3525    58456    17367  ...      0.324324      0.370817      0.340450   \n",
       "104     3611    60616    17832  ...      0.377778      0.337012      0.349814   \n",
       "105     3703    62148    18370  ...      0.362963      0.382710      0.353646   \n",
       "106     3747    63779    18827  ...      0.376000      0.364507      0.353944   \n",
       "\n",
       "     sentiment_UT  sentiment_VT  sentiment_VA  sentiment_WA  sentiment_WV  \\\n",
       "0        0.277778      0.285714      0.376000      0.370130      0.230769   \n",
       "1        0.278571      0.200000      0.279935      0.274775      0.257426   \n",
       "2        0.339450      0.309091      0.341695      0.344907      0.317690   \n",
       "3        0.320000      0.397959      0.296499      0.304866      0.280702   \n",
       "4        0.282692      0.375000      0.273628      0.305022      0.229167   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "102      0.371560      0.312775      0.347455      0.367414      0.361798   \n",
       "103      0.356223      0.410853      0.360413      0.380318      0.378495   \n",
       "104      0.376359      0.330855      0.358974      0.384506      0.322785   \n",
       "105      0.410891      0.380952      0.379421      0.392800      0.381818   \n",
       "106      0.418848      0.381579      0.391559      0.383536      0.389728   \n",
       "\n",
       "     sentiment_WI  sentiment_WY  \n",
       "0        0.283582      0.000000  \n",
       "1        0.190476      0.333333  \n",
       "2        0.293168      0.280255  \n",
       "3        0.291310      0.236111  \n",
       "4        0.247159      0.232558  \n",
       "..            ...           ...  \n",
       "102      0.334796      0.263514  \n",
       "103      0.367030      0.386207  \n",
       "104      0.369231      0.344828  \n",
       "105      0.374449      0.461078  \n",
       "106      0.378561      0.295455  \n",
       "\n",
       "[107 rows x 157 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_overall_data =  pd.concat([df_overall, df_state_overall.reindex(df_overall.index)], axis=1)\n",
    "df_overall_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output data\n",
    "df_overall_data.to_csv('csv/vader/us_case_tweet_sentiment_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate data:\n",
    "# sentiment\n",
    "d_sentiments_all_state = dict()\n",
    "for key, value in zip(states_full_dic.values(), df_sentiment_all.values()):\n",
    "    d_sentiments_all_state[key] = value\n",
    "df_sentiments_all_state_one = pd.DataFrame(data=d_sentiments_all_state)\n",
    "\n",
    "\n",
    "df_sentiments_all_states = df_overall\n",
    "df_sentiments_all_states = df_sentiments_all_states[['date', 'sentiment_us']]\n",
    "\n",
    "df_sentiments_all_states_out =  pd.concat([df_sentiments_all_states, df_sentiments_all_state_one.reindex(df_overall.index)], axis=1)\n",
    "\n",
    "#output data\n",
    "df_sentiments_all_states_out.to_csv('csv/vader/us_sentiments_analysis.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
